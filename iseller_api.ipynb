{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f5004ee-a596-4ee5-8f26-ec748c4effc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a65fa80e-dcca-457f-9935-eb3f34b0f3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# customer repeat orders -customer_id\n",
    "\n",
    "with open(\"iseller_api_response.json\", \"r\") as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6ed8502-5590-417c-a0d3-d521c584eae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_list_dictionary(dictionary):\n",
    "    normalized_dict_list = []\n",
    "    for element in dictionary:\n",
    "        num_orders = len(element)\n",
    "        index = 0\n",
    "        while num_orders > index:\n",
    "            normalized_dict_list.append(element[index])\n",
    "            index += 1\n",
    "    # Remove Keys with None values\n",
    "    filtered_orders_dict = [order for order in normalized_dict_list if order is not None]\n",
    "    return filtered_orders_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0df52b4b-65fb-417e-b98a-fe7df5d9903f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proccess_iseller_data(data):\n",
    "    orders_df = pd.DataFrame(data['orders'])\n",
    "    \n",
    "    order_details_dict = orders_df[\"order_details\"].to_list()\n",
    "    normalized_order_details = normalize_list_dictionary(order_details_dict)\n",
    "    order_details = pd.DataFrame(normalized_order_details)\n",
    "\n",
    "    #rename columns, grand_total_amount refers to the entire amount of the whole order while total_order_amount refers to total product for a product type\n",
    "    orders_df.rename(columns = {'total_order_amount':' grand_total_amount'}, inplace = True) \n",
    "\n",
    "    #merge columns\n",
    "    relevant_order_details = order_details[[\"order_id\", \"product_id\", \"product_name\", \"product_type\", \"fulfillment_status\", \"quantity\", \"base_price\", \"total_order_amount\"]]\n",
    "    merged_orders = orders_df.merge(relevant_order_details, how=\"left\", on=\"order_id\")\n",
    "    \n",
    "    # convert to correct dtypes\n",
    "    merged_orders['order_date'] = pd.to_datetime(merged_orders['order_date'])\n",
    "    merged_orders['closed_date'] = pd.to_datetime(merged_orders['closed_date'])\n",
    "\n",
    "    return merged_orders\n",
    "\n",
    "\n",
    "def get_list_json(input_folder):\n",
    "    # Initialize a list to store all JSON data\n",
    "    all_data = []\n",
    "\n",
    "    # Iterate through each JSON file in the folder\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith('.json'):\n",
    "            file_path = os.path.join(input_folder, filename)\n",
    "            with open(file_path, 'r', encoding='utf-8') as json_file:\n",
    "                data = json.load(json_file)\n",
    "                if isinstance(data, list):\n",
    "                    all_data.extend(data)\n",
    "                elif isinstance(data, dict):\n",
    "                    all_data.append(data)\n",
    "\n",
    "    return all_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d39a75cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_volume(product_name):\n",
    "    volume_regex = r'(\\d+(\\.\\d+)?\\s*(ml|l))'  # Regex pattern to match both 'ml' and 'l' formats\n",
    "    #match = re.search(volume_regex, product_name)\n",
    "    match = re.search(volume_regex, str(product_name))  # Ensure product_name is converted to string\n",
    "\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return 'unspecified'\n",
    "    \n",
    "def clean_product_name(product_name):\n",
    "    # volume_regex = r'\\b\\d+(\\.\\d+)?\\s*(ml|l)\\b'  # '\\b' for word boundaries\n",
    "    # pattern = r'\\b\\d+(\\.\\d+)?\\s*(ml|l)\\b|bli - |gof - '  # '\\b' for word boundaries\n",
    "    pattern = r'\\b\\d+(\\.\\d+)?\\s*(ml|l)\\b|bli - |gof - |- resell ecer| - resell dus|-resell dus|- dus|cabang - '  # '\\b' for word boundaries\n",
    "\n",
    "    return re.sub(pattern, '', str(product_name))  # Ensure product_name is converted to string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc02fca3-ceea-4453-8cca-60c49b9f2e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store list of json data \n",
    "list_json_data = get_list_json('data/raw_data')\n",
    "test_json = list_json_data[:5]\n",
    "list_df = []\n",
    "\n",
    "# concat list of df \n",
    "for i in list_json_data:\n",
    "    df = proccess_iseller_data(i)\n",
    "    list_df.append(df)\n",
    "\n",
    "full_iseller_data = pd.concat(list_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "230ac66c-a802-4225-868f-4fb475bc6a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_iseller_data['order_date'] = pd.to_datetime(full_iseller_data['order_date'])\n",
    "full_iseller_data['hour'] = full_iseller_data['order_date'].dt.hour\n",
    "full_iseller_data['day'] = full_iseller_data['order_date'].dt.day\n",
    "full_iseller_data['month'] = full_iseller_data['order_date'].dt.month\n",
    "full_iseller_data['week'] = full_iseller_data['order_date'].dt.isocalendar().week\n",
    "full_iseller_data['Quarter'] = full_iseller_data['order_date'].dt.quarter\n",
    "\n",
    "\n",
    "# get location columns, get coordinates ?\n",
    "full_iseller_data['location'] = full_iseller_data['outlet_name'].str.split(' - ').str[0]\n",
    "\n",
    "\n",
    "# standardize naming\n",
    "full_iseller_data['product_name'] = full_iseller_data['product_name'].str.lower()\n",
    "full_iseller_data['Volume'] = full_iseller_data['product_name'].apply(extract_volume)\n",
    "full_iseller_data['clean_product_name'] = full_iseller_data['product_name'].apply(clean_product_name)\n",
    "full_iseller_data['clean_product_name'] = full_iseller_data['clean_product_name'].str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5e3beb5-b5a9-4c18-8697-b92a319ddd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_iseller_data.to_csv('full_iseller_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d90526f7-0a6f-4a11-be54-c62ba3d8aa5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Order:  2024-01-01 00:03:37\n",
      "Latest Order:  2024-05-09 12:12:41\n"
     ]
    }
   ],
   "source": [
    "print(\"First Order: \", full_iseller_data[\"order_date\"].min())\n",
    "print(\"Latest Order: \", full_iseller_data[\"order_date\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "842d94d3-f51a-46e0-bbca-1a910e9405af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_iseller_data.sort_values(by=\"order_date\", ascending=True).tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f329dd2-3b67-4f97-bb76-30eb3b6e7bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# anggur merah gold cap orang tua anggur merah premium\tanggur kolesom 17.5% cap orang tua are these (are all amer cap orang tua)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
